{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097cda4f-0fa5-4d7c-9a41-ad59932b1785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import html\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from google.cloud import translate_v2 as translate\n",
    "from concurrent.futures import ThreadPoolExecutor    # Concurrent execution using threads\n",
    "gcp_project_id = \"artful-tractor-338209\"   # Set the Google Cloud Project ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b443f39a-6bf7-4750-ba2c-c3ecab3cc701",
   "metadata": {},
   "source": [
    "## Create a Service Account:\n",
    "After setting up project, enabling cloud translation api and setting billing account, In the Cloud Console, navigate to \"IAM & Admin\" > \"Service accounts.\" Click \"Create Service Account.\" Enter a name for service account, select the role(s) that service account needs (Cloud Translation API Editor), and click \"Continue.\"\n",
    "\n",
    "## Generate Key:\n",
    "After creating the service account, click on it in the \"Service accounts\" page. Navigate to the \"Keys\" tab. Click on \"Add Key\" and choose \"JSON.\" This will download a JSON key file containing the necessary credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85da1c90-309c-4b95-a8e3-af8ecec5985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give path to json key file\n",
    "\n",
    "credential_path = \"C:/Users/karti/Desktop/ComputerScience/internships/Nirant2/artful-tractor-338209-61f5638878ce.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97763fa3-8fe8-4bdd-bf0b-1dc5e578473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide dataset name among ai2_arc, gsm8k, lukaemon/mmlu\n",
    "dataset_name = \"ai2_arc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23549aec-5101-4c70-ae89-04ef6cabad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(dataset_name == \"ai2_arc\"):\n",
    "    possible_configs = [\n",
    "    'ARC-Challenge',\n",
    "    'ARC-Easy'\n",
    "    ]\n",
    "    # columns to translate\n",
    "    columns = ['question','choices']\n",
    "    # columns not to translate, to keep in converted dataset as is.\n",
    "    columns_asis = ['id','answerKey']\n",
    "\n",
    "elif(dataset_name == \"gsm8k\"):\n",
    "    possible_configs = [\n",
    "    \"main\",\n",
    "    \"socratic\"\n",
    "    ]\n",
    "    # columns to translate\n",
    "    columns = ['question','answer']\n",
    "    # columns not to translate, to keep in converted dataset as is.\n",
    "    columns_asis = []\n",
    "    \n",
    "elif(dataset_name == \"lukaemon/mmlu\"):\n",
    "    possible_configs = [\n",
    "    \"high_school_european_history\",\n",
    "    \"business_ethics\",\n",
    "    \"clinical_knowledge\",\n",
    "    \"medical_genetics\",\n",
    "    \"high_school_us_history\",\n",
    "    # \"high_school_physics\",\n",
    "    # \"high_school_world_history\",\n",
    "    # \"virology\",\n",
    "    # \"high_school_microeconomics\",\n",
    "    # \"econometrics\",\n",
    "    # \"college_computer_science\",\n",
    "    # \"high_school_biology\",\n",
    "    # \"abstract_algebra\",\n",
    "    # \"professional_accounting\",\n",
    "    # \"philosophy\",\n",
    "    # \"professional_medicine\",\n",
    "    # \"nutrition\",\n",
    "    # \"global_facts\",\n",
    "    # \"machine_learning\",\n",
    "    # \"security_studies\",\n",
    "    # \"public_relations\",\n",
    "    # \"professional_psychology\",\n",
    "    # \"prehistory\",\n",
    "    # \"anatomy\",\n",
    "    # \"human_sexuality\",\n",
    "    # \"college_medicine\",\n",
    "    # \"high_school_government_and_politics\",\n",
    "    # \"college_chemistry\",\n",
    "    # \"logical_fallacies\",\n",
    "    # \"high_school_geography\",\n",
    "    # \"elementary_mathematics\",\n",
    "    # \"human_aging\",\n",
    "    # \"college_mathematics\",\n",
    "    # \"high_school_psychology\",\n",
    "    # \"formal_logic\",\n",
    "    # \"high_school_statistics\",\n",
    "    # \"international_law\",\n",
    "    # \"high_school_mathematics\",\n",
    "    # \"high_school_computer_science\",\n",
    "    # \"conceptual_physics\",\n",
    "    # \"miscellaneous\",\n",
    "    # \"high_school_chemistry\",\n",
    "    # \"marketing\",\n",
    "    # \"professional_law\",\n",
    "    # \"management\",\n",
    "    # \"college_physics\",\n",
    "    # \"jurisprudence\",\n",
    "    # \"world_religions\",\n",
    "    # \"sociology\",\n",
    "    # \"us_foreign_policy\",\n",
    "    # \"high_school_macroeconomics\",\n",
    "    # \"computer_security\",\n",
    "    # \"moral_scenarios\",\n",
    "    # \"moral_disputes\",\n",
    "    # \"electrical_engineering\",\n",
    "    # \"astronomy\",\n",
    "    # \"college_biology\"\n",
    "    ]\n",
    "    # columns to translate\n",
    "    columns = ['input','A','B','C','D']\n",
    "    # columns not to translate, to keep in converted dataset as is.\n",
    "    columns_asis = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae42486-d82e-4393-a2de-7e79d18c9aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/karti/.cache/huggingface/datasets/parquet/default-94e720c37a295035/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014b5aa8edbd4c3383a25f7e98bfea50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/karti/.cache/huggingface/datasets/parquet/default-648555a0f98e748d/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc66d0f742f4d379b190d17a8ed2f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = []\n",
    "if(dataset_name == \"ai2_arc\"):\n",
    "    for config in possible_configs:\n",
    "        base_url = f\"https://huggingface.co/api/datasets/allenai/ai2_arc/parquet/{config}\"\n",
    "        data_files = {\"train\": base_url + \"/train/0.parquet\",\"test\":base_url + \"/test/0.parquet\", \"validation\": base_url + \"/validation/0.parquet\"}\n",
    "        dataset_slice = load_dataset(\"parquet\", data_files=data_files)\n",
    "        dataset.append(dataset_slice)\n",
    "elif(dataset_name == \"gsm8k\"):\n",
    "    for config in possible_configs:\n",
    "        base_url = f\"https://huggingface.co/api/datasets/gsm8k/parquet/{config}\"\n",
    "        data_files = {\"train\": base_url + \"/train/0.parquet\",\"test\":base_url + \"/test/0.parquet\"}\n",
    "        dataset_slice = load_dataset(\"parquet\", data_files=data_files)\n",
    "        dataset.append(dataset_slice)\n",
    "elif(dataset_name == \"lukaemon/mmlu\"):\n",
    "    for config in possible_configs:\n",
    "        dataset_slice = load_dataset(dataset_name, config,ignore_verifications=True)\n",
    "        dataset.append(dataset_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab2527e-1618-4307-9f8a-1001424110bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'कार्तिक आप कैसे हैं?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate_text( text: str,target='hi') -> dict:\n",
    "    \"\"\"Translates text into the target language.\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(text, target_language=target)\n",
    "\n",
    "    # html.unescape corrects translated symbols such as ', <,> etc.\n",
    "    return html.unescape(result[\"translatedText\"])\n",
    "    \n",
    "translate_text(\"How are you kartik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66993fe2-21c1-4f3b-9a72-f06f201db4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.22 s\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if(dataset_name=='lukaemon/mmlu'):\n",
    "    os.makedirs(\"lukaemon_mmlu_files\", exist_ok=True)\n",
    "    os.chdir(\"lukaemon_mmlu_files\")\n",
    "else:\n",
    "    os.makedirs(dataset_name + \"_files\", exist_ok=True)\n",
    "    os.chdir(dataset_name + \"_files\")\n",
    "\n",
    "for i in range(len(possible_configs)):\n",
    "    for set in dataset[i]:\n",
    "        set_list = []\n",
    "        \n",
    "        for col in columns:\n",
    "            values = [str(item[col]) for item in dataset[i][set]]\n",
    "            \n",
    "            # Use ThreadPoolExecutor for parallel translation\n",
    "            if __name__ == '__main__':\n",
    "                result =[]\n",
    "                with ThreadPoolExecutor(max_workers=16) as exe:\n",
    "                    # Maps the method with a list of values.\n",
    "                    # result = list(exe.map(translate_text,values[:2]))\n",
    "                    \n",
    "                    batch_size = 1\n",
    "                    for j in range(0,len(values[:2]),batch_size):\n",
    "                        j_end = min(j + batch_size, len(values[:2]))\n",
    "                        res = list(exe.map(translate_text,values[j:j_end]))\n",
    "                        # time.sleep(2)\n",
    "                        result.extend(res)\n",
    "                    \n",
    "            set_list.append(result)\n",
    "\n",
    "        # Create folders for each configuration\n",
    "        current_directory = os.getcwd()\n",
    "        \n",
    "        # Specify the path of the 'config' folder\n",
    "        config_folder_path = os.path.join(current_directory, possible_configs[i])\n",
    "        \n",
    "        # Create the 'config' folder\n",
    "        os.makedirs(config_folder_path, exist_ok=True)       \n",
    "    \n",
    "        # Transpose the 2D list\n",
    "        transposed_data = list(map(list, zip(*set_list)))\n",
    "        \n",
    "        # to add untranslated columns in dataset\n",
    "        for row in range(len(transposed_data)):\n",
    "            for col in columns_asis:\n",
    "                if col=='id':\n",
    "                        position = 0\n",
    "                else:\n",
    "                    position = len(transposed_data[row])\n",
    "                transposed_data[row].insert(position, dataset[i][set][col][row]) \n",
    "        \n",
    "            \n",
    "        path = os.path.join(possible_configs[i], f'{set}.csv')\n",
    "\n",
    "        # append to previosly created csv file in case full dataset was not converted\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            # using csv.writer method from CSV package\n",
    "            write = csv.writer(f)\n",
    "            # write.writerow(columns)\n",
    "            write.writerows(transposed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f061fc06-3759-41f9-8358-381dc4deb6f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCAS_2000_4_6</td>\n",
       "      <td>कौन सी तकनीक सबसे हाल ही में विकसित की गई थी?</td>\n",
       "      <td>{'पाठ': ['सेलुलर टेलीफोन', 'टेलीविजन', 'रेफ्रि...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mercury_7057260</td>\n",
       "      <td>एक छात्र की परिकल्पना है कि शैवाल उत्पादक हैं।...</td>\n",
       "      <td>{'पाठ': ['क्या शैवाल अन्य जीवों का उपभोग करते ...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                                                  1  \\\n",
       "0    MCAS_2000_4_6      कौन सी तकनीक सबसे हाल ही में विकसित की गई थी?   \n",
       "1  Mercury_7057260  एक छात्र की परिकल्पना है कि शैवाल उत्पादक हैं।...   \n",
       "\n",
       "                                                   2  3  \n",
       "0  {'पाठ': ['सेलुलर टेलीफोन', 'टेलीविजन', 'रेफ्रि...  A  \n",
       "1  {'पाठ': ['क्या शैवाल अन्य जीवों का उपभोग करते ...  C  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path, header=None)\n",
    "\n",
    "# Print the DataFrame\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
