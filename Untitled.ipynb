{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7436ff03-af39-4c1b-95b4-fab5b956fd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# provide dataset name among ai2_arc, gsm8k, lukaemon/mmlu\n",
    "dataset_name = \"ai2_arc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "818cb012-4ec7-4c2d-a061-f2948699571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(dataset_name == \"ai2_arc\"):\n",
    "    possible_configs = [\n",
    "    'ARC-Challenge',\n",
    "    'ARC-Easy'\n",
    "    ]\n",
    "    # columns to translate\n",
    "    columns = ['question','choices']\n",
    "    # columns not to translate, to keep in converted dataset as is.\n",
    "    columns_asis = ['id','answerKey']\n",
    "\n",
    "elif(dataset_name == \"gsm8k\"):\n",
    "    possible_configs = [\n",
    "    \"main\",\n",
    "    \"socratic\"\n",
    "    ]\n",
    "    # columns to translate\n",
    "    columns = ['question','answer']\n",
    "    # columns not to translate, to keep in converted dataset as is.\n",
    "    columns_asis = []\n",
    "    \n",
    "elif(dataset_name == \"lukaemon/mmlu\"):\n",
    "    possible_configs = [\n",
    "    \"high_school_european_history\",\n",
    "    \"business_ethics\",\n",
    "    \"clinical_knowledge\",\n",
    "    # \"medical_genetics\",\n",
    "    # \"high_school_us_history\",\n",
    "    # \"high_school_physics\",\n",
    "    # \"high_school_world_history\",\n",
    "    # \"virology\",\n",
    "    # \"high_school_microeconomics\",\n",
    "    # \"econometrics\",\n",
    "    # \"college_computer_science\",\n",
    "    # \"high_school_biology\",\n",
    "    # \"abstract_algebra\",\n",
    "    # \"professional_accounting\",\n",
    "    # \"philosophy\",\n",
    "    # \"professional_medicine\",\n",
    "    # \"nutrition\",\n",
    "    # \"global_facts\",\n",
    "    # \"machine_learning\",\n",
    "    # \"security_studies\",\n",
    "    # \"public_relations\",\n",
    "    # \"professional_psychology\",\n",
    "    # \"prehistory\",\n",
    "    # \"anatomy\",\n",
    "    # \"human_sexuality\",\n",
    "    # \"college_medicine\",\n",
    "    # \"high_school_government_and_politics\",\n",
    "    # \"college_chemistry\",\n",
    "    # \"logical_fallacies\",\n",
    "    # \"high_school_geography\",\n",
    "    # \"elementary_mathematics\",\n",
    "    # \"human_aging\",\n",
    "    # \"college_mathematics\",\n",
    "    # \"high_school_psychology\",\n",
    "    # \"formal_logic\",\n",
    "    # \"high_school_statistics\",\n",
    "    # \"international_law\",\n",
    "    # \"high_school_mathematics\",\n",
    "    # \"high_school_computer_science\",\n",
    "    # \"conceptual_physics\",\n",
    "    # \"miscellaneous\",\n",
    "    # \"high_school_chemistry\",\n",
    "    # \"marketing\",\n",
    "    # \"professional_law\",\n",
    "    # \"management\",\n",
    "    # \"college_physics\",\n",
    "    # \"jurisprudence\",\n",
    "    # \"world_religions\",\n",
    "    # \"sociology\",\n",
    "    # \"us_foreign_policy\",\n",
    "    # \"high_school_macroeconomics\",\n",
    "    # \"computer_security\",\n",
    "    # \"moral_scenarios\",\n",
    "    # \"moral_disputes\",\n",
    "    # \"electrical_engineering\",\n",
    "    # \"astronomy\",\n",
    "    # \"college_biology\",\n",
    "    ]\n",
    "    # columns to translate\n",
    "    columns = ['input','A','B','C','D']\n",
    "    # columns not to translate, to keep in converted dataset as is.\n",
    "    columns_asis = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5aeaec1-22a0-4ecd-adeb-7f9753e7637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/karti/.cache/huggingface/datasets/parquet/default-94e720c37a295035/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187b3cacabb84b6599dfdf1b84aff060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/karti/.cache/huggingface/datasets/parquet/default-648555a0f98e748d/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b93d5108914c64a130a950979a537a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = []\n",
    "if(dataset_name == \"ai2_arc\"):\n",
    "    for config in possible_configs:\n",
    "        base_url = f\"https://huggingface.co/api/datasets/allenai/ai2_arc/parquet/{config}\"\n",
    "        data_files = {\"train\": base_url + \"/train/0.parquet\",\"test\":base_url + \"/test/0.parquet\", \"validation\": base_url + \"/validation/0.parquet\"}\n",
    "        dataset_slice = load_dataset(\"parquet\", data_files=data_files)\n",
    "        dataset.append(dataset_slice)\n",
    "elif(dataset_name == \"gsm8k\"):\n",
    "    for config in possible_configs:\n",
    "        base_url = f\"https://huggingface.co/api/datasets/gsm8k/parquet/{config}\"\n",
    "        data_files = {\"train\": base_url + \"/train/0.parquet\",\"test\":base_url + \"/test/0.parquet\"}\n",
    "        dataset_slice = load_dataset(\"parquet\", data_files=data_files)\n",
    "        dataset.append(dataset_slice)\n",
    "elif(dataset_name == \"lukaemon/mmlu\"):\n",
    "    for config in possible_configs:\n",
    "        dataset_slice = load_dataset(dataset_name, config,ignore_verifications=True)\n",
    "        dataset.append(dataset_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5524618-4a76-4499-bcba-c79c5bde9e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 1119\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 1172\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 299\n",
      "    })\n",
      "}), DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 2251\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 2376\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 570\n",
      "    })\n",
      "})]\n"
     ]
    }
   ],
   "source": [
    "# print(dataset[1]['train'][0])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b2ec9f1-d82d-496d-a932-e09840b3e21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai2_arc\n",
      "ai2_arc ['ARC-Challenge', 'ARC-Easy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/karti/.cache/huggingface/datasets/parquet/default-94e720c37a295035/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02aa26aff65341d28c77e7ffe8a311c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/karti/.cache/huggingface/datasets/parquet/default-648555a0f98e748d/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655f73956d9e463ca2cb705d178c8538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 1119\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 1172\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 299\n",
      "    })\n",
      "}), DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 2251\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 2376\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'choices', 'answerKey'],\n",
      "        num_rows: 570\n",
      "    })\n",
      "})]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    from datasets import load_dataset\n",
    "    dataset_name = 'ai2_arc'\n",
    "    print(dataset_name)\n",
    "    \n",
    "    if(dataset_name == \"ai2_arc\"):\n",
    "        possible_configs = [\n",
    "        'ARC-Challenge',\n",
    "        'ARC-Easy'\n",
    "        ]\n",
    "        # columns to translate\n",
    "        columns = ['question','choices']\n",
    "        # columns not to translate, to keep in converted dataset as is.\n",
    "        columns_asis = ['id','answerKey']\n",
    "    \n",
    "    elif(dataset_name == \"gsm8k\"):\n",
    "        possible_configs = [\n",
    "        \"main\",\n",
    "        \"socratic\"\n",
    "        ]\n",
    "        # columns to translate\n",
    "        columns = ['question','answer']\n",
    "        # columns not to translate, to keep in converted dataset as is.\n",
    "        columns_asis = []\n",
    "        \n",
    "    elif(dataset_name == \"lukaemon/mmlu\"):\n",
    "        possible_configs = [\n",
    "        \"high_school_european_history\",\n",
    "        \"business_ethics\",\n",
    "        \"clinical_knowledge\",\n",
    "        \"medical_genetics\",\n",
    "        ]\n",
    "        # columns to translate\n",
    "        columns = ['input','A','B','C','D']\n",
    "        # columns not to translate, to keep in converted dataset as is.\n",
    "        columns_asis = ['target']\n",
    "    print(dataset_name, possible_configs)\n",
    "    \n",
    "    dataset = []\n",
    "    if(dataset_name == \"ai2_arc\"):\n",
    "        for config in possible_configs:\n",
    "            base_url = f\"https://huggingface.co/api/datasets/allenai/ai2_arc/parquet/{config}\"\n",
    "            data_files = {\"train\": base_url + \"/train/0.parquet\",\"test\":base_url + \"/test/0.parquet\", \"validation\": base_url + \"/validation/0.parquet\"}\n",
    "            dataset_slice = load_dataset(\"parquet\", data_files=data_files)\n",
    "            dataset.append(dataset_slice)\n",
    "    elif(dataset_name == \"gsm8k\"):\n",
    "        for config in possible_configs:\n",
    "            base_url = f\"https://huggingface.co/api/datasets/gsm8k/parquet/{config}\"\n",
    "            data_files = {\"train\": base_url + \"/train/0.parquet\",\"test\":base_url + \"/test/0.parquet\"}\n",
    "            dataset_slice = load_dataset(\"parquet\", data_files=data_files)\n",
    "            dataset.append(dataset_slice)\n",
    "    elif(dataset_name == \"lukaemon/mmlu\"):\n",
    "        for config in possible_configs:\n",
    "            dataset_slice = load_dataset(dataset_name, config,ignore_verifications=True)\n",
    "            dataset.append(dataset_slice)\n",
    "    print(dataset)\n",
    "\n",
    "    \n",
    "except Exception as e:\n",
    "    # Handle the exception\n",
    "    print('An error occurred:'+ str(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20865f8a-8af2-48da-8f75-5918a92b4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://huggingface.co/api/datasets/gsm8k/parquet\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
