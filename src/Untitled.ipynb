{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c23a492-335d-4951-a736-7856919efa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'IndicTrans2'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AI4Bharat/IndicTrans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5096870-4325-485c-9033-977da6abd1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\Desktop\\ComputerScience\\internships\\Nirant2\\indic-llm-eval\\src\\IndicTrans2\\huggingface_interface\n"
     ]
    }
   ],
   "source": [
    "%cd IndicTrans2/huggingface_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38d740db-b7b4-408d-a2b7-cdba219ea5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\karti\\\\Desktop\\\\ComputerScience\\\\internships\\\\Nirant2\\\\indic-llm-eval\\\\src\\\\IndicTrans2\\\\huggingface_interface'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f3bc5a5-992f-44ff-afff-7b1ae50899dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'IndicProcessor' from 'IndicTransTokenizer' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSeq2SeqLM, BitsAndBytesConfig\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIndicTransTokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndicProcessor, IndicTransTokenizer\n\u001b[0;32m      6\u001b[0m en_indic_ckpt_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai4bharat/indictrans2-en-indic-1B\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# ai4bharat/indictrans2-en-indic-dist-200M\u001b[39;00m\n\u001b[0;32m      7\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'IndicProcessor' from 'IndicTransTokenizer' (unknown location)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "from IndicTransTokenizer import IndicProcessor, IndicTransTokenizer\n",
    "\n",
    "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    quantization = sys.argv[1]\n",
    "else:\n",
    "    quantization = \"\"\n",
    "\n",
    "\n",
    "def initialize_model_and_tokenizer(ckpt_dir, direction, quantization):\n",
    "    if quantization == \"4-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    elif quantization == \"8-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            bnb_8bit_use_double_quant=True,\n",
    "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    else:\n",
    "        qconfig = None\n",
    "\n",
    "    tokenizer = IndicTransTokenizer(direction=direction)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        quantization_config=qconfig,\n",
    "    )\n",
    "\n",
    "    if qconfig == None:\n",
    "        model = model.to(DEVICE)\n",
    "        model.half()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip):\n",
    "    translations = []\n",
    "    for i in range(0, len(input_sentences), BATCH_SIZE):\n",
    "        batch = input_sentences[i : i + BATCH_SIZE]\n",
    "\n",
    "        # Preprocess the batch and extract entity mappings\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "        # Tokenize the batch and generate input encodings\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            src=True,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # Generate translations using the model\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=0,\n",
    "                max_length=256,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1,\n",
    "            )\n",
    "\n",
    "        # Decode the generated tokens into text\n",
    "        generated_tokens = tokenizer.batch_decode(generated_tokens.detach().cpu().tolist(), src=False)\n",
    "\n",
    "        # Postprocess the translations, including entity replacement\n",
    "        translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return translations\n",
    "\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"en-indic\", quantization)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "#                              English to Hindi\n",
    "# ---------------------------------------------------------------------------\n",
    "en_sents = [\n",
    "    \"When I was young, I used to go to the park every day.\",\n",
    "    \"He has many old books, which he inherited from his ancestors.\",\n",
    "    \"I can't figure out how to solve my problem.\",\n",
    "    \"She is very hardworking and intelligent, which is why she got all the good marks.\",\n",
    "    \"We watched a new movie last week, which was very inspiring.\",\n",
    "    \"If you had met me at that time, we would have gone out to eat.\",\n",
    "    \"She went to the market with her sister to buy a new sari.\",\n",
    "    \"Raj told me that he is going to his grandmother's house next month.\",\n",
    "    \"All the kids were having fun at the party and were eating lots of sweets.\",\n",
    "    \"My friend has invited me to his birthday party, and I will give him a gift.\",\n",
    "]\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"hin_Deva\"\n",
    "hi_translations = batch_translate(en_sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\n",
    "\n",
    "print(f\"\\n{src_lang} - {tgt_lang}\")\n",
    "for input_sentence, translation in zip(en_sents, hi_translations):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
