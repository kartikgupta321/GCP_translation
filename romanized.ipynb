{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de44fb1-a0f3-4ed5-920b-fb235d702aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from concurrent.futures import ThreadPoolExecutor    # Concurrent execution using threads\n",
    "gcp_project_id = \"artful-tractor-338209\"   # Set the Google Cloud Project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f973bdfe-c262-41ef-a31d-ef8d2e7789c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide dataset name among ai2_arc, gsm8k, lukaemon/mmlu, bbc_hindi_nli(for testing hindi to hinglish)\n",
    "dataset_name = \"bbc_hindi_nli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9bf7946-4590-49d8-9a9e-e88155b85016",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(dataset_name == \"ai2_arc\"):\n",
    "    possible_configs = [\n",
    "    'ARC-Challenge',\n",
    "    'ARC-Easy'\n",
    "    ]\n",
    "elif(dataset_name == \"gsm8k\"):\n",
    "    possible_configs = [\n",
    "    \"main\",\n",
    "    \"socratic\"\n",
    "    ]\n",
    "elif(dataset_name == \"lukaemon/mmlu\"):\n",
    "    possible_configs = [\n",
    "    \"high_school_european_history\",\n",
    "    \"business_ethics\",\n",
    "    \"clinical_knowledge\",\n",
    "    \"medical_genetics\",\n",
    "    \"high_school_us_history\",\n",
    "    \"high_school_physics\",\n",
    "    \"high_school_world_history\",\n",
    "    \"virology\",\n",
    "    \"high_school_microeconomics\",\n",
    "    \"econometrics\",\n",
    "    \"college_computer_science\",\n",
    "    \"high_school_biology\",\n",
    "    \"abstract_algebra\",\n",
    "    \"professional_accounting\",\n",
    "    \"philosophy\",\n",
    "    \"professional_medicine\",\n",
    "    \"nutrition\",\n",
    "    \"global_facts\",\n",
    "    \"machine_learning\",\n",
    "    \"security_studies\",\n",
    "    \"public_relations\",\n",
    "    \"professional_psychology\",\n",
    "    \"prehistory\",\n",
    "    \"anatomy\",\n",
    "    \"human_sexuality\",\n",
    "    \"college_medicine\",\n",
    "    \"high_school_government_and_politics\",\n",
    "    \"college_chemistry\",\n",
    "    \"logical_fallacies\",\n",
    "    \"high_school_geography\",\n",
    "    \"elementary_mathematics\",\n",
    "    \"human_aging\",\n",
    "    \"college_mathematics\",\n",
    "    \"high_school_psychology\",\n",
    "    \"formal_logic\",\n",
    "    \"high_school_statistics\",\n",
    "    \"international_law\",\n",
    "    \"high_school_mathematics\",\n",
    "    \"high_school_computer_science\",\n",
    "    \"conceptual_physics\",\n",
    "    \"miscellaneous\",\n",
    "    \"high_school_chemistry\",\n",
    "    \"marketing\",\n",
    "    \"professional_law\",\n",
    "    \"management\",\n",
    "    \"college_physics\",\n",
    "    \"jurisprudence\",\n",
    "    \"world_religions\",\n",
    "    \"sociology\",\n",
    "    \"us_foreign_policy\",\n",
    "    \"high_school_macroeconomics\",\n",
    "    \"computer_security\",\n",
    "    \"moral_scenarios\",\n",
    "    \"moral_disputes\",\n",
    "    \"electrical_engineering\",\n",
    "    \"astronomy\",\n",
    "    \"college_biology\",\n",
    "    ]\n",
    "elif(dataset_name == \"bbc_hindi_nli\"):\n",
    "    possible_configs = [\n",
    "    \"bbc hindi nli\"\n",
    "    ]\n",
    "    # columns to translate\n",
    "    columns = ['premise','hypothesis']\n",
    "    # columns not to translate, to keep in converted dataset as is.\n",
    "    columns_asis = ['label','topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978de591-db1e-422e-a1aa-85c177e90653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1760: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb64925ec0f43bab4f1f6397470ce68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/bbc hindi nli to C:/Users/karti/.cache/huggingface/datasets/parquet/bbc hindi nli-c5e28bba7f715fdf/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37bd34c31c0488f8efad8d6055a219d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f53d83b80c745feb92f4e9da56a80a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/266k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd06bad13d0143c0a4915579cd25a043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f7bffb548b4e1a9b497c73c478474b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7e6440585741e2bdc8686825b96893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/15552 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2592 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to C:/Users/karti/.cache/huggingface/datasets/parquet/bbc hindi nli-c5e28bba7f715fdf/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d4255fa0ff4c8586c461ab93560073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = []\n",
    "for config in possible_configs:\n",
    "    dataset_slice = load_dataset(\"bbc_hindi_nli\", config,ignore_verifications=True)\n",
    "    dataset.append(dataset_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "112e3ac3-9952-4b87-8018-540bd69910af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label', 'topic'],\n",
      "    num_rows: 15552\n",
      "})\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label', 'topic'],\n",
      "    num_rows: 2592\n",
      "})\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label', 'topic'],\n",
      "    num_rows: 2580\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "for g in dataset:\n",
    "    print(g['train'])\n",
    "    print(g['test'])\n",
    "    print(g['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c82ba4b-e7d5-4857-a4cb-d65217aa92d2",
   "metadata": {},
   "source": [
    "## Get access token for romanization\n",
    "\n",
    "1. go to link https://developers.google.com/oauthplayground/ \n",
    "2. select Cloud Translation API v3, under it select both https://www.googleapis.com/auth/cloud-platform\n",
    "https://www.googleapis.com/auth/cloud-translation\n",
    "3. authorize\n",
    "4. exchange authorization code for tokens and copy the access token.\n",
    "\n",
    "   #### valid for one hour only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e4038f-e2db-41b9-8238-28f7d82d5089",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = 'ya29.a0AfB_byBvm1OheATW_139gkhWA7A7eBXG8uZRcMmUyjEXMmBjaebMzVaxlTXXAGJSvSLDS1SxkaGFpViizMtfMlMsB5DHBetdbSiM2gO-H2HdyJmTeaF-OYI2r94yb83k01WigkxB9yErQGnKwD5s4aMM96Ri3uemrhnRaCgYKAUASARASFQHGX2MivUrMpO0a92cuLTn67UitpQ0171'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe919be-e680-4032-ab52-ae4f8c39f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def romanize( text: str):\n",
    "    url = 'https://translation.googleapis.com/v3/projects/artful-tractor-338209/locations/global:romanizeText'\n",
    "\n",
    "    headers = {\n",
    "    'Authorization': f'Bearer {access_token}',\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json',\n",
    "    }\n",
    "    data = {\n",
    "    'contents': [text],\n",
    "    'sourceLanguageCode': 'hi',\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        romanized_text = result['romanizations'][0]['romanizedText']\n",
    "        return f'{romanized_text}'\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb15e67-1c65-41c1-b23e-92fec0470a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kaartik aap kaise hain?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romanize(\"कार्तिक आप कैसे हैं?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9d3a378-0d82-45bd-8dc5-45dfd755bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.23 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if(dataset_name=='lukaemon/mmlu'):\n",
    "    os.makedirs(\"lukaemon_mmlu_files\", exist_ok=True)\n",
    "    os.chdir(\"lukaemon_mmlu_files\")\n",
    "else:\n",
    "    os.makedirs(dataset_name + \"_files\", exist_ok=True)\n",
    "    os.chdir(dataset_name + \"_files\")\n",
    "\n",
    "for i in range(len(possible_configs)):\n",
    "    for set in dataset[i]:\n",
    "        set_list = []\n",
    "        \n",
    "        for col in columns:\n",
    "            values = [str(item[col]) for item in dataset[i][set]]\n",
    "            \n",
    "            # Use ThreadPoolExecutor for parallel translation\n",
    "            if __name__ == '__main__':\n",
    "                result =[]\n",
    "                with ThreadPoolExecutor(max_workers=16) as exe:\n",
    "                    # Maps the method with a list of values.\n",
    "                    # result = list(exe.map(romanize,values[10:12]))\n",
    "                    \n",
    "                    batch_size = 1\n",
    "                    for j in range(0,len(values[:3]),batch_size):\n",
    "                        j_end = min(j + batch_size, len(values[:3]))\n",
    "                        res = list(exe.map(romanize,values[j:j_end]))\n",
    "                        # time.sleep(2)\n",
    "                        result.extend(res)\n",
    "                    \n",
    "            set_list.append(result)\n",
    "\n",
    "        # Create folders for each configuration\n",
    "        current_directory = os.getcwd()\n",
    "        \n",
    "        # Specify the path of the 'config' folder\n",
    "        config_folder_path = os.path.join(current_directory, possible_configs[i])\n",
    "        \n",
    "        # Create the 'config' folder\n",
    "        os.makedirs(config_folder_path, exist_ok=True)       \n",
    "    \n",
    "        # Transpose the 2D list\n",
    "        transposed_data = list(map(list, zip(*set_list)))\n",
    "\n",
    "        # to add untranslated columns in dataset\n",
    "        for row in range(len(transposed_data)):\n",
    "            for col in columns_asis:\n",
    "                if col=='id':\n",
    "                        position = 0\n",
    "                else:\n",
    "                    position = len(transposed_data[row])\n",
    "                transposed_data[row].insert(position, dataset[i][set][col][row]) \n",
    "        \n",
    "        path = os.path.join(possible_configs[i], f'{set}.csv')\n",
    "\n",
    "        # append to previosly created csv file in case full dataset was not converted\n",
    "        with open(path, 'a', encoding='utf-8') as f:\n",
    "            # using csv.writer method from CSV package\n",
    "            write = csv.writer(f)\n",
    "            # write.writerow(columns)\n",
    "            write.writerows(transposed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7502a1e5-1b17-4a51-a577-cbd88085a7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bam dhamaakon se dahala iraak, darjanon mare</td>\n",
       "      <td>yah bhaarat kee soochana hai|</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bam dhamaakon se dahala iraak, darjanon mare</td>\n",
       "      <td>yah bhaarat kee soochana nahin hai|</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bam dhamaakon se dahala iraak, darjanon mare</td>\n",
       "      <td>yah khabar kee soochana hai|</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0  \\\n",
       "0  bam dhamaakon se dahala iraak, darjanon mare   \n",
       "1  bam dhamaakon se dahala iraak, darjanon mare   \n",
       "2  bam dhamaakon se dahala iraak, darjanon mare   \n",
       "\n",
       "                                     1  2  3  \n",
       "0        yah bhaarat kee soochana hai|  0  2  \n",
       "1  yah bhaarat kee soochana nahin hai|  1  2  \n",
       "2         yah khabar kee soochana hai|  0  2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path, header=None)\n",
    "\n",
    "# Print the DataFrame\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
