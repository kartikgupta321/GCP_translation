{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0042a34-fd20-4d17-a35c-0110779f00e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from concurrent.futures import ThreadPoolExecutor    # Concurrent execution using threads\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c65ade-617e-40d8-822e-c41683a892e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712bf570-0037-4eb2-aa5e-39771ff7e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide dataset name among ai2_arc, gsm8k, lukaemon/mmlu\n",
    "dataset_name = \"ai2_arc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cebb71-1cf9-4f17-b6df-0e43c1a73781",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(dataset_name == \"ai2_arc\"):\n",
    "    possible_configs = [\n",
    "    'ARC-Challenge',\n",
    "    'ARC-Easy'\n",
    "    ]\n",
    "    # columns to translate\n",
    "    columns = ['question','choices']\n",
    "    # columns not to translate, to keep in converted dataset as is.\n",
    "    columns_asis = ['id','answerKey']\n",
    "\n",
    "elif(dataset_name == \"gsm8k\"):\n",
    "    possible_configs = [\n",
    "    \"main\",\n",
    "    \"socratic\"\n",
    "    ]\n",
    "    # columns to translate\n",
    "    columns = ['question','answer']\n",
    "    # columns not to translate, to keep in converted dataset as is.\n",
    "    columns_asis = []\n",
    "    \n",
    "elif(dataset_name == \"lukaemon/mmlu\"):\n",
    "    possible_configs = [\n",
    "    \"high_school_european_history\",\n",
    "    \"business_ethics\",\n",
    "    \"clinical_knowledge\",\n",
    "    \"medical_genetics\",\n",
    "    \"high_school_us_history\",\n",
    "    # \"high_school_physics\",\n",
    "    # \"high_school_world_history\",\n",
    "    # \"virology\",\n",
    "    # \"high_school_microeconomics\",\n",
    "    # \"econometrics\",\n",
    "    # \"college_computer_science\",\n",
    "    # \"high_school_biology\",\n",
    "    # \"abstract_algebra\",\n",
    "    # \"professional_accounting\",\n",
    "    # \"philosophy\",\n",
    "    # \"professional_medicine\",\n",
    "    # \"nutrition\",\n",
    "    # \"global_facts\",\n",
    "    # \"machine_learning\",\n",
    "    # \"security_studies\",\n",
    "    # \"public_relations\",\n",
    "    # \"professional_psychology\",\n",
    "    # \"prehistory\",\n",
    "    # \"anatomy\",\n",
    "    # \"human_sexuality\",\n",
    "    # \"college_medicine\",\n",
    "    # \"high_school_government_and_politics\",\n",
    "    # \"college_chemistry\",\n",
    "    # \"logical_fallacies\",\n",
    "    # \"high_school_geography\",\n",
    "    # \"elementary_mathematics\",\n",
    "    # \"human_aging\",\n",
    "    # \"college_mathematics\",\n",
    "    # \"high_school_psychology\",\n",
    "    # \"formal_logic\",\n",
    "    # \"high_school_statistics\",\n",
    "    # \"international_law\",\n",
    "    # \"high_school_mathematics\",\n",
    "    # \"high_school_computer_science\",\n",
    "    # \"conceptual_physics\",\n",
    "    # \"miscellaneous\",\n",
    "    # \"high_school_chemistry\",\n",
    "    # \"marketing\",\n",
    "    # \"professional_law\",\n",
    "    # \"management\",\n",
    "    # \"college_physics\",\n",
    "    # \"jurisprudence\",\n",
    "    # \"world_religions\",\n",
    "    # \"sociology\",\n",
    "    # \"us_foreign_policy\",\n",
    "    # \"high_school_macroeconomics\",\n",
    "    # \"computer_security\",\n",
    "    # \"moral_scenarios\",\n",
    "    # \"moral_disputes\",\n",
    "    # \"electrical_engineering\",\n",
    "    # \"astronomy\",\n",
    "    # \"college_biology\",\n",
    "    ]\n",
    "    # columns to translate\n",
    "    columns = ['input','A','B','C','D']\n",
    "    # columns not to translate, to keep in converted dataset as is.\n",
    "    columns_asis = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "433dd18b-3b68-4d10-be42-4a02f01a2097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/karti/.cache/huggingface/datasets/parquet/default-94e720c37a295035/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64fb9ac20a147ef966f641de613f70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/karti/.cache/huggingface/datasets/parquet/default-648555a0f98e748d/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b578b000d87a480d8b7e3f8344f41c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = []\n",
    "if(dataset_name == \"ai2_arc\"):\n",
    "    for config in possible_configs:\n",
    "        base_url = f\"https://huggingface.co/api/datasets/allenai/ai2_arc/parquet/{config}\"\n",
    "        data_files = {\"train\": base_url + \"/train/0.parquet\",\"test\":base_url + \"/test/0.parquet\", \"validation\": base_url + \"/validation/0.parquet\"}\n",
    "        dataset_slice = load_dataset(\"parquet\", data_files=data_files)\n",
    "        dataset.append(dataset_slice)\n",
    "elif(dataset_name == \"gsm8k\"):\n",
    "    for config in possible_configs:\n",
    "        base_url = f\"https://huggingface.co/api/datasets/gsm8k/parquet/{config}\"\n",
    "        data_files = {\"train\": base_url + \"/train/0.parquet\",\"test\":base_url + \"/test/0.parquet\"}\n",
    "        dataset_slice = load_dataset(\"parquet\", data_files=data_files)\n",
    "        dataset.append(dataset_slice)\n",
    "elif(dataset_name == \"lukaemon/mmlu\"):\n",
    "    for config in possible_configs:\n",
    "        dataset_slice = load_dataset(dataset_name, config,ignore_verifications=True)\n",
    "        dataset.append(dataset_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7326f435-ceb9-46a6-9968-5d08da04f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "def translate_gpt(text: str):\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": \"translate the given text in english to hinglish.(written in english alphabet but sounding like reading hindi language)\"},\n",
    "            {\"role\": \"system\", \"content\": \"if input is 'how are you' return 'kaise ho ap'\"},\n",
    "            # {\"role\": \"system\", \"content\": \"if input is 'Add a new weekly reminder for Sunday Brunch at 9 : 30 am' return '9 : 30 am ko Sunday Brunch ke liye ek naya weekly reminder add karen'\"},\n",
    "            # {\"role\": \"system\", \"content\": \"if input is 'Using the timer to find out how long this 5K race will take me' return '5k ki daud me mujhe kitna samay lagega ye jaanne ke liye timer ka use karo'\"},\n",
    "            # {\"role\": \"system\", \"content\": \"if input is 'how long will it take to get to richmond' return 'richmond tak jane ke liye kitni der lagegi'\"},\n",
    "            {\"role\": \"system\", \"content\": \"suppose you are a native hindi speaker who also speaks english, but since most phones offer english keyboard by default you choose to write hindi in english letters. return the input english texts in hinglish\"},\n",
    "            {\"role\": \"system\", \"content\": \"if input is '{ 'text': [ 'cooling of flowing magma.', 'converging of crustal plates.', 'deposition of river sediments.', 'solution of carbonate minerals.' ], 'label': [ 'A', 'B', 'C', 'D' ] }' return '{ 'text': [ 'flowing magma ka thnda hone.', 'crustal plates ka converge hona.', 'river sediments ka deposition hona.', 'carbonate minerals ka solution.' ], 'label': [ 'A', 'B', 'C', 'D' ] }'\"},\n",
    "            {\"role\": \"system\", \"content\": \"if input is 'The end result in the process of photosynthesis is the production of sugar and oxygen. Which step signals the beginning of photosynthesis' return 'photosynthesis process ke last m sugar aur oxygen produce hota h, kis step se photosynthesis ke start hone ka pta chlta h'\"},  \n",
    "            {\"role\": \"system\", \"content\": \"numbers, nouns, verbs stay in English and rest is in Hindi. Do not give original text back\"},\n",
    "            {\"role\": \"system\", \"content\": \"do not translate to hindi, translate to hinglish\"},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b2cbe9a-8b93-47d8-aedf-de10e6e5c8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"text\": [ \"flowing magma ka thanda hona.\", \"crustal plates ka converge hona.\", \"river sediments ka deposition hona.\", \"carbonate minerals ka solution hona.\" ], \"label\": [ \"A\", \"B\", \"C\", \"D\" ] }'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_gpt('{ \"text\": [ \"cooling of flowing magma.\", \"converging of crustal plates.\", \"deposition of river sediments.\", \"solution of carbonate minerals.\" ], \"label\": [ \"A\", \"B\", \"C\", \"D\" ] }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4437556a-4f17-4d1e-a0b6-30e352703d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The end result in the process of photosynthesis is the production of sugar aur oxygen. Kaunsa step photosynthesis ka start hone ka signal deta hai?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_gpt('The end result in the process of photosynthesis is the production of sugar and oxygen. Which step signals the beginning of photosynthesis?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b43139-f87c-407b-bbf7-08d22d77dc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kaise ho ap'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_gpt('how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e282f8fe-d30c-4290-9856-d14b562ae4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 594 ms\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if(dataset_name=='lukaemon/mmlu'):\n",
    "    os.makedirs(\"lukaemon_mmlu_files\", exist_ok=True)\n",
    "    os.chdir(\"lukaemon_mmlu_files\")\n",
    "else:\n",
    "    os.makedirs(dataset_name + \"_files\", exist_ok=True)\n",
    "    os.chdir(dataset_name + \"_files\")\n",
    "\n",
    "for i in range(len(possible_configs)):\n",
    "    for set in dataset[i]:\n",
    "        set_list = []\n",
    "        \n",
    "        for col in columns:\n",
    "            values = [str(item[col]) for item in dataset[i][set]]\n",
    "            \n",
    "            # Use ThreadPoolExecutor for parallel translation\n",
    "            if __name__ == '__main__':\n",
    "                result =[]\n",
    "                with ThreadPoolExecutor(max_workers=16) as exe:\n",
    "                    # Maps the method with a list of values.\n",
    "                    # result = list(exe.map(translate_gpt,values[:1]))\n",
    "                    \n",
    "                    batch_size = 1\n",
    "                    for j in range(0,len(values[:3]),batch_size):\n",
    "                        j_end = min(j + batch_size, len(values[:1]))\n",
    "                        res = list(exe.map(translate_gpt,values[j:j_end]))\n",
    "                        # time.sleep(2)\n",
    "                        result.extend(res)\n",
    "                    \n",
    "            set_list.append(result)\n",
    "\n",
    "        # Create folders for each configuration\n",
    "        current_directory = os.getcwd()\n",
    "        \n",
    "        # Specify the path of the 'config' folder\n",
    "        config_folder_path = os.path.join(current_directory, possible_configs[i])\n",
    "        \n",
    "        # Create the 'config' folder\n",
    "        os.makedirs(config_folder_path, exist_ok=True) \n",
    "    \n",
    "        # Transpose the 2D list\n",
    "        transposed_data = list(map(list, zip(*set_list)))\n",
    "        \n",
    "        # to add untranslated columns in dataset\n",
    "        for row in range(len(transposed_data)):\n",
    "            for col in columns_asis:\n",
    "                if col=='id':\n",
    "                        position = 0\n",
    "                else:\n",
    "                    position = len(transposed_data[row])\n",
    "                transposed_data[row].insert(position, dataset[i][set][col][row]) \n",
    "        \n",
    "            \n",
    "        path = os.path.join(possible_configs[i], f'{set}.csv')\n",
    "\n",
    "        # append to previosly created csv file in case full dataset was not converted\n",
    "        with open(path, 'a', encoding='utf-8') as f:\n",
    "            # using csv.writer method from CSV package\n",
    "            write = csv.writer(f)\n",
    "            # write.writerow(columns)\n",
    "            write.writerows(transposed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a26677e3-511f-46ed-91e1-a8eedeb80bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARC-Easy\\validation.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCAS_2000_4_6</td>\n",
       "      <td>kaunsi technology sabse haal hi mein develop h...</td>\n",
       "      <td>{'text': ['cellular telephone', 'television', ...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                                                  1  \\\n",
       "0  MCAS_2000_4_6  kaunsi technology sabse haal hi mein develop h...   \n",
       "\n",
       "                                                   2  3  \n",
       "0  {'text': ['cellular telephone', 'television', ...  A  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path, header=None)\n",
    "\n",
    "# Print the DataFrame\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
